{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e436fa85-e27d-468c-adac-3799c8bfcd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['VAEVAE' '0.33416265']\n",
      " ['VVVVEE' '0.47900775']\n",
      " ['AVVVEE' '0.40672958']\n",
      " ['EVAAVE' '0.3973079']\n",
      " ['WVKAK' '0.882486']\n",
      " ['AWKK' '0.7290055']\n",
      " ['YLGSRK' '0.7318606']\n",
      " ['IISGKK' '0.9247904']\n",
      " ['VSVMDD' '0.87586594']\n",
      " ['HIVRR' '0.76570314']\n",
      " ['EVEAEE' '0.3732991']\n",
      " ['EVEEVE' '0.40254655']\n",
      " ['LSLDDD' '0.8764509']\n",
      " ['DVLDD' '0.65832806']\n",
      " ['VILLRK' '0.896657']]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Generate fiber forming sequences using the ML model \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "############################## ML predict fiber ##############################\n",
    "\n",
    "\n",
    "OUTPUT_SEQ_LEN       = 1\n",
    "INPUT_DIM            = 20\n",
    "OUTPUT_DIM           = 1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def cal_feature_matrix(data, max_peplen, res_dict):\n",
    "    \"\"\"Convert peptide seqs into a feature matrix\n",
    "    Accepts python array or list \n",
    "    \"\"\"\n",
    "    data_feature = np.zeros((len(data), max_peplen, len(res_dict)))\n",
    "    for i,seq in enumerate(data):\n",
    "        for j,res in enumerate(seq[:max_peplen]):\n",
    "            data_feature[i,j,res_dict[res]] = 1\n",
    "    return data_feature\n",
    "\n",
    "\n",
    "def featurization(seqs):\n",
    "    \"\"\" encodes each residue into a 1-hot vector \"\"\"\n",
    "    # Residue Dictionary\n",
    "    residues = ['G', 'A', 'V', 'S', 'T', 'L', 'I', 'M', 'P', 'F', 'Y', 'W', 'N', 'Q', 'H', 'K', 'R', 'E', 'D', 'C']\n",
    "    res_dict = {}\n",
    "    for i,r in enumerate(residues):\n",
    "        res_dict[r] = i\n",
    "    max_peplen = 10\n",
    "    X = cal_feature_matrix(seqs, max_peplen, res_dict)\n",
    "    X = X.astype(float)\n",
    "    return X, seqs\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    \"\"\" ML model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        dropout = 0.4\n",
    "        self.hidden_size = 200\n",
    "        self.num_layers = 1\n",
    "        input_size = INPUT_DIM\n",
    "        self.lstm = torch.nn.LSTM(input_size, self.hidden_size, self.num_layers, dropout=0, batch_first=True)\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(self.hidden_size,OUTPUT_DIM),\n",
    "            torch.nn.Sigmoid()\n",
    "            )\n",
    "        self.num_params = 0\n",
    "        self.num_params += sum(p.numel() for p in self.lstm.parameters() if p.requires_grad)\n",
    "        self.num_params += sum(p.numel() for p in self.fc.parameters() if p.requires_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers,len(x),self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers,len(x),self.hidden_size).to(device)\n",
    "        out, (h, c) = self.lstm(x, (h0, c0))\n",
    "        z = self.fc(out[:,-1,:])\n",
    "        return z\n",
    "\n",
    "\n",
    "def ml_predict(seqs):\n",
    "    \"\"\" seqs is a list/array of peptide sequence of the PA. \n",
    "    e.g. seq is VVAAEE for the PA C16V2A2E2 \"\"\"\n",
    "\n",
    "    f = featurization(seqs)\n",
    "    X, seqs = f[0], f[1]\n",
    "    checkpoint = torch.load('model.tar')\n",
    "    model = Model().to(device)\n",
    "    model.load_state_dict(checkpoint['best_model_state_dict'])\n",
    "    model.eval()\n",
    "    x = torch.tensor(X).float()\n",
    "    z = model(x).detach().numpy()\n",
    "    \n",
    "    return seqs, z.reshape(-1)\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "\n",
    "def main():\n",
    "    # does what you want to do\n",
    "\n",
    "    seqs = [\n",
    "    'VAEVAE', 'VVVVEE', 'AVVVEE', 'EVAAVE', 'WVKAK', 'AWKK', 'YLGSRK', 'IISGKK', \n",
    "    'VSVMDD', 'HIVRR', 'EVEAEE', 'EVEEVE', 'LSLDDD', 'DVLDD', 'VILLRK']\n",
    "    _, z = ml_predict(seqs)\n",
    "    \n",
    "    print(np.array(list(zip(seqs,z))))\n",
    "\n",
    "\n",
    "\n",
    "main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc384367-dcfa-4217-9e18-62379e9fa8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
